{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join, realpath, dirname, exists, abspath, isfile, isdir\n",
    "from os import mkdir as mk, name as os_name, getcwd, environ, pathsep, rename, listdir\n",
    "from wget import download\n",
    "from uuid import uuid1\n",
    "from time import sleep\n",
    "import tensorflow as tf\n",
    "import cv2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Definitions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings & Options ðŸ”§\n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
    "PRETRAINED_MODEL_ZIP_NAME = f'{PRETRAINED_MODEL_NAME}.tar.gz'\n",
    "API_MODELS_URL = 'https://github.com/tensorflow/models'\n",
    "PROTOC_VERSION = '3.15.6'\n",
    "PROTOC_URL = f'https://github.com/protocolbuffers/protobuf/releases/download/v{PROTOC_VERSION}/protoc-{PROTOC_VERSION}-win64.zip'\n",
    "PROTOC_ZIP_NAME = f'protoc-{PROTOC_VERSION}-win64.zip'\n",
    "MODEL_NAME = 'model-v1' # current model name being used within 'workspace/models' directory\n",
    "LATEST_CHECKPOINT = 11\n",
    "BATCH_SIZE = 8\n",
    "TRAINING_STEPS = 10_000\n",
    "\n",
    "# Paths ðŸ“‚\n",
    "ROOT_DIR = getcwd()\n",
    "API_MODELS_DIR = join(ROOT_DIR, 'models')\n",
    "API_RESEARCH_DIR = join(API_MODELS_DIR, 'research')\n",
    "API_OBJECT_DETECTION_DIR = join(API_RESEARCH_DIR, 'object_detection')\n",
    "API_SETUP_SCRIPT_PATH = join(API_OBJECT_DETECTION_DIR, 'packages', 'tf2', 'setup.py')\n",
    "API_VERIFICATION_SCRIPT_PATH = join(API_OBJECT_DETECTION_DIR, 'builders', 'model_builder_tf2_test.py')\n",
    "API_SLIM_DIR = join(API_RESEARCH_DIR, 'slim')\n",
    "PROTOC_DIR = join(ROOT_DIR, 'protoc')\n",
    "PROTOC_BIN_DIR = join(PROTOC_DIR, 'bin')\n",
    "TRAIN_SCRIPT_PATH = join(API_MODELS_DIR, 'research', 'object_detection', 'model_main_tf2.py')\n",
    "WORKSPACE_DIR = join(ROOT_DIR, 'workspace')\n",
    "MODELS_DIR = join(WORKSPACE_DIR, 'models')\n",
    "PRETRAINED_MODELS_DIR = join(WORKSPACE_DIR, 'pre-trained-models')\n",
    "SCRIPTS_DIR = join(ROOT_DIR, 'scripts')\n",
    "TF_RECORD_SCRIPT_PATH = join(SCRIPTS_DIR, 'generate_tfrecord.py')\n",
    "LABELMAP_SCRIPT_PATH = join(SCRIPTS_DIR, 'generate_labelmap.py')\n",
    "IMAGES_DIR = join(WORKSPACE_DIR, 'images')\n",
    "TEST_IMAGES_DIR = join(IMAGES_DIR, 'test')\n",
    "TRAIN_IMAGES_DIR = join(IMAGES_DIR, 'train')\n",
    "VALIDATION_IMAGES_DIR = join(IMAGES_DIR, 'validation')\n",
    "LABELING_IMAGES_DIR = join(IMAGES_DIR, 'labeling')\n",
    "COLLECTED_IMAGES_DIR = join(LABELING_IMAGES_DIR, 'collected')\n",
    "CAPTURED_IMAGES_DIR = join(IMAGES_DIR, 'captured')\n",
    "ANNOTATIONS_DIR = join(WORKSPACE_DIR, 'annotations')\n",
    "LABELMAP_PATH = join(ANNOTATIONS_DIR, 'label_map.pbtxt')\n",
    "TRAIN_TF_RECORD_PATH = join(ANNOTATIONS_DIR, 'train.record')\n",
    "TEST_TF_RECORD_PATH = join(ANNOTATIONS_DIR, 'test.record')\n",
    "MODEL_DIR = join(MODELS_DIR, MODEL_NAME)\n",
    "PRETRAINED_MODEL_DIR = join(PRETRAINED_MODELS_DIR, PRETRAINED_MODEL_NAME)\n",
    "PRETRAINED_CONFIG_PATH = join(PRETRAINED_MODEL_DIR, 'pipeline.config')\n",
    "PRETRAINED_CHECKPOINT_PATH = join(PRETRAINED_MODEL_DIR, 'checkpoint', 'ckpt-0')\n",
    "MODEL_CONFIG_PATH = join(MODEL_DIR, 'pipeline.config')\n",
    "CURRENT_CP_PATH = join(MODEL_DIR, f'ckpt-{LATEST_CHECKPOINT}')\n",
    "\n",
    "# Constants ðŸ§®\n",
    "SIGNS = [\n",
    "  # letters\n",
    "  'a', 'b', 'c', 'd',\n",
    "  \n",
    "  # words\n",
    "  'llamar', 'caminar', 'comunicar', 'ladron'\n",
    "  \n",
    "  # phrases\n",
    "  \n",
    "]\n",
    "\n",
    "# Util ðŸ†˜\n",
    "def mkdir(path: str, debug=False):\n",
    "  if not exists(path):\n",
    "    mk(path)\n",
    "  else:\n",
    "    if debug:\n",
    "      print(f'{path} already exists!')\n",
    "\n",
    "def r(path: str):\n",
    "  return path.replace('\\\\', '/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Capturing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options\n",
    "SNAPSHOTS = 10\n",
    "WAIT_PER_SIGN = 5\n",
    "WAIT_PER_SNAPSHOT = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capturing all signs!\n",
    "cap = cv2.VideoCapture(0) # NOTE: change '0' if camera device is not being picked up\n",
    "\n",
    "for sign in SINGS:\n",
    "  print(f'Capturing sign {sign} in {WAIT_PER_SIGN}s')\n",
    "  sleep(WAIT_PER_SIGN)\n",
    "\n",
    "  for i in range(SNAPSHOTS):\n",
    "    print(f'Collecting image {i + 1} for sign {sign} in {WAIT_PER_SNAPSHOT}')\n",
    "    sleep(WAIT_PER_SNAPSHOT)\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    img_path = join(CAPTURED_IMAGES_DIR, f'{sign}.{uuid1()}.jpg')\n",
    "    cv2.imwrite(img_path, frame)\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capturing single sign!\n",
    "cap = cv2.VideoCapture(0) # NOTE: change '0' if camera device is not being picked up\n",
    "sign = 'a'\n",
    "\n",
    "\n",
    "print(f'Capturing sign {sign} in {WAIT_PER_SIGN}s')\n",
    "sleep(WAIT_PER_SIGN)\n",
    "\n",
    "for i in range(SNAPSHOTS):\n",
    "  print(f'Collecting image {i + 1} for sign {sign} in {WAIT_PER_SNAPSHOT}')\n",
    "  sleep(WAIT_PER_SNAPSHOT)\n",
    "  \n",
    "  ret, frame = cap.read()\n",
    "  img_path = join(CAPTURED_IMAGES_DIR, f'{sign}.{uuid1()}.jpg')\n",
    "  cv2.imwrite(img_path, frame)\n",
    "  cv2.imshow('frame', frame)\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Raw Image Preping**\n",
    "> *Renames and prepares images for labeling*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SINGLE FOLDER\n",
    "_SIGN = 'a'\n",
    "SIGN_DIR = join(LABELING_IMAGES_DIR, _SIGN)\n",
    "\n",
    "if not exists(SIGN_DIR): raise Exception(f'make sure {SIGN_DIR} exists!')\n",
    "\n",
    "for img_name in listdir(SIGN_DIR):\n",
    "  src_img_path = join(SIGN_DIR, img_name)\n",
    "  if isfile(src_img_path):\n",
    "    dest_img_path = join(COLLECTED_IMAGES_DIR, f'{_SIGN}.{uuid1()}.jpg')\n",
    "    rename(src_img_path, dest_img_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL FOLDERS\n",
    "for _SIGN in listdir(LABELING_IMAGES_DIR):\n",
    "  if _SIGN == 'collected': continue\n",
    "  \n",
    "  SIGN_DIR = join(LABELING_IMAGES_DIR, _SIGN)\n",
    "  if not exists(SIGN_DIR): raise Exception(f'make sure {SIGN_DIR} exists!')\n",
    "\n",
    "  for img_name in listdir(SIGN_DIR):\n",
    "    src_img_path = join(SIGN_DIR, img_name)\n",
    "    if isfile(src_img_path):\n",
    "      dest_img_path = join(COLLECTED_IMAGES_DIR, f'{_SIGN}.{uuid1()}.jpg')\n",
    "      rename(src_img_path, dest_img_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Labeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!labelimg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Object Detection API Installation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: TEST!\n",
    "if os_name == 'posix':\n",
    "    print('using posix')\n",
    "    !apt-get install protobuf-compiler\n",
    "    !cd {API_OBJECT_DETECTION_DIR} && protoc protos/*.proto --python_out=. && cp {API_SETUP_SCRIPT_PATH} . && python -m pip install . \n",
    "\n",
    "if os_name == 'nt':\n",
    "    print('using nt')\n",
    "    download(PROTOC_URL)\n",
    "    !move {PROTOC_ZIP_NAME} {PROTOC_DIR}\n",
    "    !cd {PROTOC_DIR} && tar -xf {PROTOC_ZIP_NAME}\n",
    "    environ['PATH'] += pathsep + abspath(PROTOC_BIN_DIR)\n",
    "    RL_SCRIPT_PATH = join('object_detection', 'packages', 'tf2', 'setup.py')\n",
    "    !cd {API_RESEARCH_DIR} && protoc object_detection/protos/*.proto --python_out=. && copy {RL_SCRIPT_PATH} setup.py\n",
    "    !cd {API_RESEARCH_DIR} && python setup.py build && python setup.py install\n",
    "    !cd {API_SLIM_DIR} && pip install -e . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Installation\n",
    "!python {API_VERIFICATION_SCRIPT_PATH}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Object Detection API Imports**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **note**: *must run [Object Detection API installation](#Object_Detection_API_Installation) section and restart kernel for object_detection module to work!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.protobuf import text_format\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from object_detection.utils import config_util as cu\n",
    "from object_detection.utils import label_map_util as lu\n",
    "from object_detection.builders import model_builder as mb\n",
    "from object_detection.utils import visualization_utils as vu"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Setup pre-trained Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: TEST!\n",
    "if os_name =='posix':\n",
    "  print('using posix')\n",
    "  !wget {PRETRAINED_MODEL_URL}\n",
    "  !mv {PRETRAINED_MODEL_NAME + '.tar.gz'} {PRETRAINED_MODELS_DIR}\n",
    "  !cd {PRETRAINED_MODELS_DIR} && tar -zxvf {PRETRAINED_MODEL_NAME + '.tar.gz'}\n",
    "\n",
    "if os_name == 'nt':\n",
    "  print('using nt')\n",
    "  download(PRETRAINED_MODEL_URL)\n",
    "  !move { PRETRAINED_MODEL_NAME + '.tar.gz' } {PRETRAINED_MODELS_DIR}\n",
    "  !cd {PRETRAINED_MODELS_DIR} && tar -zxvf {PRETRAINED_MODEL_NAME + '.tar.gz'}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Set up model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir(MODEL_DIR)\n",
    "\n",
    "if os_name =='posix':\n",
    "  print('using posix')\n",
    "  !cp {PRETRAINED_CONFIG_PATH} {MODEL_DIR}\n",
    "\n",
    "if os_name == 'nt':\n",
    "  print('using nt')\n",
    "  !copy {PRETRAINED_CONFIG_PATH} {MODEL_DIR}\n",
    "\n",
    "config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "\n",
    "with tf.io.gfile.GFile(MODEL_CONFIG_PATH, \"r\") as f:                                                                                                                                                                                                                     \n",
    "  proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "  text_format.Merge(proto_str, config)\n",
    "    \n",
    "config.model.ssd.num_classes = len(SIGNS)\n",
    "config.train_config.batch_size = BATCH_SIZE\n",
    "config.train_config.fine_tune_checkpoint = PRETRAINED_CHECKPOINT_PATH\n",
    "config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "config.train_config.use_bfloat16 = False\n",
    "config.train_input_reader.label_map_path= LABELMAP_PATH\n",
    "config.train_input_reader.tf_record_input_reader.input_path[:] = [TRAIN_TF_RECORD_PATH]\n",
    "config.eval_input_reader[0].label_map_path = LABELMAP_PATH\n",
    "config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [TEST_TF_RECORD_PATH]\n",
    "\n",
    "config_text = text_format.MessageToString(config)\n",
    "with tf.io.gfile.GFile(MODEL_CONFIG_PATH, \"wb\") as f:\n",
    "  f.write(config_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Prep-train**\n",
    "> **note**: *make sure you've labeled and partition your dataset*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Generating Label Map**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(LABELMAP_PATH, 'w') as f:\n",
    "  id = 0\n",
    "  for sign in SIGNS:\n",
    "    id += 1\n",
    "    f.write('item { \\n')\n",
    "    f.write(f'\\tname: \\'{sign}\\'\\n')\n",
    "    f.write(f'\\tid: {id}\\n')\n",
    "    f.write('}\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Generating TF Records**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python {TF_RECORD_SCRIPT_PATH} -x {TEST_IMAGES_DIR} -l {LABELMAP_PATH} -o {TEST_TF_RECORD_PATH} \n",
    "!python {TF_RECORD_SCRIPT_PATH} -x {TRAIN_IMAGES_DIR} -l {LABELMAP_PATH} -o {TRAIN_TF_RECORD_PATH} "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cmd line\n",
    "POSIX_SHELL = True\n",
    "tensorboard_cmd = f'tensorboard --logdir={MODEL_DIR}'\n",
    "train_cmd = f'python {TRAIN_SCRIPT_PATH} --model_dir={MODEL_DIR} --pipeline_config_path={MODEL_CONFIG_PATH} --num_train_steps={TRAINING_STEPS}'\n",
    "print('run the following command(s):\\n')\n",
    "print(r(tensorboard_cmd) if POSIX_SHELL else tensorboard_cmd)\n",
    "print('\\n')\n",
    "print(r(train_cmd) if POSIX_SHELL else train_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from jupyter (NOT RECOMMENDED)\n",
    "!tensorboard --logdir={MODEL_DIR}\n",
    "!python {TRAIN_SCRIPT_PATH} --model_dir={MODEL_DIR} --pipeline_config_path={MODEL_CONFIG_PATH} --num_train_steps={TRAINING_STEPS}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **note**: *its going to take a while depending on the* `BATCH_SIZE`, `TRAINNING_STEPS` *and whether you're using a GPU or not*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Detecting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load pipeline config and build a detection model\n",
    "configs = cu.get_configs_from_pipeline_file(MODEL_CONFIG_PATH)\n",
    "detection_model = mb.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(CURRENT_CP_PATH).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "  image, shapes = detection_model.preprocess(image)\n",
    "  prediction_dict = detection_model.predict(image, shapes)\n",
    "  detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "  return detections\n",
    "\n",
    "category_index = lu.create_category_index_from_labelmap(LABELMAP_PATH)\n",
    "\n",
    "# Setup capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while True: \n",
    "  ret, frame = cap.read()\n",
    "  image_np = np.array(frame)\n",
    "  \n",
    "  input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "  detections = detect_fn(input_tensor)\n",
    "  \n",
    "  num_detections = int(detections.pop('num_detections'))\n",
    "  detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()}\n",
    "  detections['num_detections'] = num_detections\n",
    "\n",
    "  # detection_classes should be ints.\n",
    "  detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "  label_id_offset = 1\n",
    "  image_np_with_detections = image_np.copy()\n",
    "\n",
    "  vu.visualize_boxes_and_labels_on_image_array(\n",
    "    image_np_with_detections,\n",
    "    detections['detection_boxes'],\n",
    "    detections['detection_classes']+label_id_offset,\n",
    "    detections['detection_scores'],\n",
    "    category_index,\n",
    "    use_normalized_coordinates=True,\n",
    "    max_boxes_to_draw=5,\n",
    "    min_score_thresh=.75,\n",
    "    agnostic_mode=False\n",
    "  )\n",
    "\n",
    "  cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n",
    "  \n",
    "  if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "    cap.release()\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5220da38e0c1002fee3b34102aec99113390b34d4ab6f32dbd2aff7c281a43cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
